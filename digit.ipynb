{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Author: Gael Varoquaux <gael dot varoquaux at normalesup dot org>\n# License: BSD 3 clause\n\n# Standard scientific Python imports\nimport matplotlib.pyplot as plt\n\n# Import datasets, classifiers and performance metrics\nfrom sklearn import datasets, svm, metrics\nfrom sklearn.model_selection import train_test_split\n\n# The digits dataset\ndigits = datasets.load_digits()\n\n# The data that we are interested in is made of 8x8 images of digits, let's\n# have a look at the first 4 images, stored in the `images` attribute of the\n# dataset.  If we were working from image files, we could load them using\n# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n# images, we know which digit they represent: it is given in the 'target' of\n# the dataset.\n_, axes = plt.subplots(2, 4)\nimages_and_labels = list(zip(digits.images, digits.target))\nfor ax, (image, label) in zip(axes[0, :], images_and_labels[:4]):\n    ax.set_axis_off()\n    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n    ax.set_title('Training: %i' % label)\n\n# To apply a classifier on this data, we need to flatten the image, to\n# turn the data in a (samples, feature) matrix:\nn_samples = len(digits.images)\ndata = digits.images.reshape((n_samples, -1))\n\n# Create a classifier: a support vector classifier\nclassifier = svm.SVC(gamma=0.001)\n\n# Split data into train and test subsets\nX_train, X_test, y_train, y_test = train_test_split(\n    data, digits.target, test_size=0.5, shuffle=False)\n\n# We learn the digits on the first half of the digits\nclassifier.fit(X_train, y_train)\n\n# Now predict the value of the digit on the second half:\npredicted = classifier.predict(X_test)\n\nimages_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\nfor ax, (image, prediction) in zip(axes[1, :], images_and_predictions[:4]):\n    ax.set_axis_off()\n    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n    ax.set_title('Prediction: %i' % prediction)\n\nprint(\"Classification report for classifier %s:\\n%s\\n\"\n      % (classifier, metrics.classification_report(y_test, predicted)))\nprint(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(predicted, y_test))\n\nplt.show()","execution_count":1,"outputs":[{"output_type":"stream","text":"Classification report for classifier SVC(gamma=0.001):\n              precision    recall  f1-score   support\n\n           0       1.00      0.99      0.99        88\n           1       0.99      0.97      0.98        91\n           2       0.99      0.99      0.99        86\n           3       0.98      0.87      0.92        91\n           4       0.99      0.96      0.97        92\n           5       0.95      0.97      0.96        91\n           6       0.99      0.99      0.99        91\n           7       0.96      0.99      0.97        89\n           8       0.94      1.00      0.97        88\n           9       0.93      0.98      0.95        92\n\n    accuracy                           0.97       899\n   macro avg       0.97      0.97      0.97       899\nweighted avg       0.97      0.97      0.97       899\n\n\nConfusion matrix:\n[[87  0  0  0  0  0  0  0  0  0]\n [ 0 88  0  0  0  0  1  0  0  0]\n [ 0  1 85  0  0  0  0  0  0  0]\n [ 0  0  1 79  0  0  0  0  0  1]\n [ 1  0  0  0 88  0  0  0  0  0]\n [ 0  0  0  3  0 88  0  1  0  1]\n [ 0  0  0  0  0  1 90  0  0  0]\n [ 0  0  0  4  0  0  0 88  0  0]\n [ 0  1  0  5  0  0  0  0 88  0]\n [ 0  1  0  0  4  2  0  0  0 90]]\n","name":"stdout"},{"output_type":"display_data","data":{"application/javascript":"element.append(window._basthonDomNodeBus.pop(0));"},"metadata":{}}]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":2}